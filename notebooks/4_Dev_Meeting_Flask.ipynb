{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_Dev_Meeting_Flask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWJICkmpbW7S",
        "colab_type": "text"
      },
      "source": [
        "# DevMeeting – Data Science\n",
        "## 4. Flask\n",
        "\n",
        "Flask to minimalistyczny framework do aplikacji webowych w Pythonie. Jest to wygodne narzędzie w budowaniu prostych serwisów, np. do dostarczania modeli predykcyjnych. W niniejszym projekcie połączymy model Titanic z modelem przewidywania wieku i płci, by uzyskać serwis określający szanse przeżycia na hipotetycznym Titanicu.\n",
        "\n",
        "Niestety Colaboratory jest środowiskiem badawczym, nie budowanym z myślą o uruchamianiu serwisów, dlatego wykorzystamy narzędzie [ngrok](https://ngrok.com/) do tunelowania połączeń poza sieć lokalną Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWq-oI6bTaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from flask import Flask, request"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV4G1fKuZJHb",
        "colab_type": "code",
        "outputId": "a245f7e4-1ff8-4d32-f20a-19841b4820fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-28 12:12:16--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.72.245.79, 34.196.238.26, 52.200.123.104, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.72.245.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13607069 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  81%[===============>    ]  10.61M  52.7MB/s               \rngrok-stable-linux- 100%[===================>]  12.98M  56.7MB/s    in 0.2s    \n",
            "\n",
            "2019-09-28 12:12:16 (56.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13607069/13607069]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElbTPAqc6kKU",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Integracja modeli uczenia maszynowego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tpBly7TCvLZ",
        "colab_type": "text"
      },
      "source": [
        "Integracja modeli predykcyjnych jest ułatwiona, jeśli pracujemy w Pythonie. Możemy skorzystać z już zbudowanych modeli np. w scikit-learnie, czy TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLf0aJrF6udc",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Wstęp do Flaska"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psv5-hGVXCCI",
        "colab_type": "text"
      },
      "source": [
        "Aplikacje we Flasku wymagają utworzenia instancji klasy `Flask`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70NTvqZ7fxsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app = Flask(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s69z4HzygC6B",
        "colab_type": "text"
      },
      "source": [
        "Kolejnym etapem jest zdefiniowanie endpointów - służy do tego dekorator `@app.route`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA2ko6ajiw6x",
        "colab_type": "code",
        "outputId": "db69bdc3-75cd-4c90-d81d-5434fef63201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 5000 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "  return \"Hello world\"\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://7c539d9f.ngrok.io\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [28/Sep/2019 12:14:00] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [28/Sep/2019 12:14:01] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyinJh6flrpd",
        "colab_type": "text"
      },
      "source": [
        "Możemy określić, że endpoint działa tylko przy użyciu metody POST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJFXOrJGlP0C",
        "colab_type": "code",
        "outputId": "6fae1598-bfe5-45b7-d671-f98ec1bcc194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 5000 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/estimate\", methods=[\"POST\"])\n",
        "def estimate():\n",
        "  return \"Hello world\"\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://71802855.ngrok.io\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [28/Sep/2019 12:16:49] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [28/Sep/2019 12:16:50] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [28/Sep/2019 12:17:06] \"\u001b[1m\u001b[31mGET /estimate HTTP/1.1\u001b[0m\" 405 -\n",
            "127.0.0.1 - - [28/Sep/2019 12:17:54] \"\u001b[37mPOST /estimate HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRPgo631lyxA",
        "colab_type": "text"
      },
      "source": [
        "We Flasku możemy uzyskać dostęp do danych przesyłanych w żądaniu korzystając z globalnego obiektu [request](http://flask.pocoo.org/docs/0.12/api/#incoming-request-data).\n",
        "\n",
        "Szczególnie istotne są dla nas dwa pola tego obiektu:\n",
        " * `request.files` - słownik plików, przesłanych razem z żądaniem jako część formularza\n",
        " * `request.form` - słownik zawierający pola formularza\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9I8O9GmleId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 5000 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/estimate\", methods=[\"POST\"])\n",
        "def estimate():\n",
        "  file = request.files[\"file\"]\n",
        "  p_class = request.form[\"class\"]\n",
        "  \n",
        "  return \"Hello world\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rUHhIevi3UJ",
        "colab_type": "text"
      },
      "source": [
        "Po zdefiniowaniu endpointów wystarczy wykonać metodę `run` na obiekcie aplikacji. Uruchomiony zostanie serwer deweloperski na domyślnym porcie 5000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qbZO_jrjE3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uruchomienie metody spowoduje zablokowanie możliwości wykonywania innych komórek\n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDTOB7ofD0go",
        "colab_type": "text"
      },
      "source": [
        "# Zadania do wykonania\n",
        "\n",
        "1. Wczytaj potrzebne komponenty:\n",
        "  * model predykcji przeżywalności (pickle)\n",
        "  * model predykcji wieku i płci (jak w poprzednim etapie)\n",
        "2. Zbuduj podstwową aplikację we Flasku -- endpoint `/estimate` przyjmujący dane formularza: \n",
        "  * zdjęcie\n",
        "  * liczbę rodzeństwa/współmałżonków (siblings/spouses)\n",
        "  * liczbę dzieci/rodziców (parents/children)\n",
        "  * klasę wykupionego biletu\n",
        "3. Przygotuj potok przetwarzania:\n",
        "  * odczytanie danych z przychodzącego żądania\n",
        "  * predykcja płci i wieku\n",
        "  * przygotowanie wyniku z predykcji płci i wieku (binaryzacja)\n",
        "  * zbudowanie wektora cech dla predykcji przeżywalności\n",
        "  * predykcja przeżywalności\n",
        "  * zwrócenie wyniku"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1D_07ENXEUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from flask import Flask, request\n",
        "\n",
        "# przygotowanie tunelu\n",
        "get_ipython().system_raw('./ngrok http 5000 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# właściwa część aplikacji\n",
        "app = Flask(__name__)\n",
        "\n",
        "# 1. ładowanie modeli - powinno być wykonane w przed uruchomieniem aplikacji\n",
        "#     - sieci do predykcji wieku i płci\n",
        "#     - modelu przeżywalności: kodera etykiet i drzewa decyzyjnego\n",
        "!git clone https://github.com/dzkb/age-gender-estimation\n",
        "!wget https://github.com/dzkb/devmeeting-data-science/raw/master/models/model.pkl\n",
        "!wget https://github.com/yu4u/age-gender-estimation/releases/download/v0.5/weights.29-3.76_utk.hdf5\n",
        "\n",
        "with open(\"model.pkl\", \"rb\") as f:\n",
        "  labelEncoder, treeModel = pickle.load(f)\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"./age-gender-estimation\")\n",
        "\n",
        "\n",
        "from wide_resnet import WideResNet\n",
        "deep_model = WideResNet(image_size=64)\n",
        "deep_model = deep_model()\n",
        "deep_model.load_weights(\"/content/weights.29-3.76_utk.hdf5\")\n",
        "deep_model._make_predict_function()\n",
        "\n",
        "# miejsce na definicję endpointu\n",
        "@app.route(\"/estimate\", methods=[\"POST\"])\n",
        "def index():\n",
        "  image_file = request.files[\"image\"]\n",
        "  n_children = request.form[\"children\"]\n",
        "  n_siblings = request.form[\"siblings\"]\n",
        "  p_class = request.form[\"class\"]\n",
        "  \n",
        "  \n",
        "  img = Image.open(image_file)\n",
        "  img = img.resize((64, 64))\n",
        "  \n",
        "  np_img = np.array(img)\n",
        "  np_img = np_img.reshape((1, 64, 64, 3))\n",
        "  \n",
        "  sex, age = deep_model.predict(np_img)\n",
        "  \n",
        "  features = [p_class, np.argmax(sex), np.argmax(age), n_siblings, n_children]\n",
        "  np_features = np.array(features).reshape((1, -1))\n",
        "  \n",
        "  survival_prediction = treeModel.predict(np_features)\n",
        "  \n",
        "  # 2. przyjęcie danych z obiektu request\n",
        "  #     - zdjęcie z request.files\n",
        "  #     - pozostałe pola z request.form\n",
        "  # 3. przygotowanie obrazu do przetworzenia\n",
        "  # 4. przetworzenie obrazu i pozyskanie wartości wieku i płci\n",
        "  # 5. przygotowanie wektora wejściowego dla drzewa decyzyjnego (m. in. preprocessing)\n",
        "  # 6. przekazanie wektora do drzewa decyzyjnego\n",
        "  # 7. zwrócenie wyniku\n",
        "  \n",
        "  return str(survival_prediction)\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}